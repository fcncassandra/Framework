{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import MSELoss #Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = torch.randn(size=(50,),dtype=torch.float32)\n",
    "y = torch.randn(size=(50,),dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = MSELoss(reduction = \"sum\")\n",
    "# MSEloss(reduction = \"mean\"/\"sum\") #MSE #SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(yhat,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(86.6319)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 二分类交叉熵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 手动实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$L(w) = \\sum_{i=1}^m(y_i*ln(\\sigma_i) + (1-y_i)*ln(1-\\sigma_i))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 3*pow(10,3)\n",
    "\n",
    "torch.random.manual_seed(420)\n",
    "X = torch.rand((m,4),dtype=torch.float32)\n",
    "w = torch.rand((4,1),dtype=torch.float32)\n",
    "y = torch.randint(low=0,high=2,size=(m,1),dtype=torch.float32)\n",
    "zhat = torch.mm(X,w)\n",
    "sigma = torch.sigmoid(zhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss  = -(1/m) * sum(y * torch.log(sigma) + (1-y) * torch.log(1-sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7962])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，在写损失函数这样的复杂函数时，除了普通的加减乘除以外的全部计算，都要使用torch中的函数，因为tensor的运算速度是远远超过普通Python代码，甚至是NumPy的。你可以试着比较在样本量为300W时，以下两行代码运行的时间差异"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 3 * pow(10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((m, 4), dtype=torch.float32)\n",
    "w = torch.rand((4, 1), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.randint(low=0, high=2, size=(m,1), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        ...,\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((m,4),dtype=torch.float32)\n",
    "w = torch.rand((4,1),dtype=torch.float32)\n",
    "y = torch.randint(low=0,high=2,size=(m,1),dtype=torch.float32)\n",
    "zhat = torch.mm(X,w)\n",
    "sigma = torch.sigmoid(zhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python原生"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0851020812988281\n"
     ]
    }
   ],
   "source": [
    "start = time.time() #捕获现在的时间\n",
    "loss1 = -(1/m)*sum(y*torch.log(sigma) + (1-y)*torch.log(1-sigma))\n",
    "now = time.time() #以秒计\n",
    "print(now - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001994609832763672\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "loss2 = -(1/m)*torch.sum(y*torch.log(sigma) + (1-y)*torch.log(1-sigma))\n",
    "now = time.time() #以秒计\n",
    "print(now - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2种转成Numpy的写法\n",
    "np_sigma = torch.sigmoid(zhat).numpy() \n",
    "np_y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003989219665527344\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "loss3 = - (1/m) * np.sum(np_y*np.log(np_sigma) + (1-np_y)*np.log(1-np_sigma))\n",
    "now = time.time()\n",
    "print(now - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 交叉熵实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有nn中的2个，还有functional库中的2个，推荐nn.BCEWithLogitsLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7608)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.BCELoss(reduction = \"mean\") # none sum mean\n",
    "loss = criterion(sigma,y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7608)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pytorch官方更加推荐，因为内置的sigmoid函数可以让精度问题被缩小\n",
    "criterion2 = nn.BCEWithLogitsLoss(reduction = \"mean\")\n",
    "loss = criterion2(zhat, y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7608)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "#直接调用functional库中的计算函数\n",
    "F.binary_cross_entropy_with_logits(zhat,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7608)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.binary_cross_entropy(sigma,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 多分类交叉熵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二分类单样本使用这样的表示：$P = (\\hat y_i|x_i,w) = P_1^{y_i}*P_0^{1-y_i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多分类单样本使用这的表示：$P = (\\hat y_i|x_i,w) = P_1^{y_{i(k=1)}}*P_2^{y_{i(k=2)}}*...*P_k^{y_{i(k=K)}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于仅为真实类别时才会有结果，所以可以简化为：$P = (\\hat y_i|x_i,w) = P_j^{y_{i(k=j)}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多样本下的损失函数是：$L(w) = - \\sum_{i=1}^my_{i(k=j)}ln\\sigma_i$  \n",
    "$ln\\sigma_i$是对softmax计算的结果取Ln  \n",
    "$- \\sum_{i=1}^my_{i(k=j)}$是负对数似然函数NLLLoss：Negative Log Likelihood function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 3 * pow(10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(420)\n",
    "X = torch.rand((m, 4), dtype=torch.float32)\n",
    "w = torch.rand((4, 3), dtype=torch.float32)\n",
    "y = torch.randint(low=0, high=3, size=(m,), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_hat = torch.mm(X, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1139, -0.8802, -1.3585],\n",
       "        [-1.0558, -0.8982, -1.4075],\n",
       "        [-1.0920, -1.0626, -1.1430],\n",
       "        ...,\n",
       "        [-1.0519, -0.9180, -1.3805],\n",
       "        [-1.0945, -1.1219, -1.0798],\n",
       "        [-1.0276, -0.8891, -1.4649]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logsm = nn.LogSoftmax(dim=1)\n",
    "log_sigma = logsm(z_hat)\n",
    "log_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2.,  ..., 2., 2., 2.])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1147)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.NLLLoss() #实例化\n",
    "#由于交叉熵损失需要将标签转化为独热形式，因此不接受浮点数作为标签的输入\n",
    "#对NLLLoss而言，需要输入logsigma\n",
    "criterion(log_sigma, y.long())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用nn的更快"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1147)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(z_hat, y.long())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 反向传播和迭代"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 自动求导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(1,requires_grad=True, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(2,requires_grad=False, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = torch.sigmoid(z) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = -(y*torch.log(sigma) + (1-y)*torch.log(1-sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-2.5379),)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.grad(loss,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 搭建网络"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#3分类，500个样本，20个特征，共3层，第一层13个神经元，第二层8个神经元\n",
    "#第一层的激活函数时relu，第二层的激活函数是sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss as CEL\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#确定数据\n",
    "torch.manual_seed(420)\n",
    "X = torch.rand((500,20),dtype=torch.float32) * 100\n",
    "y = torch.randint(low=0,high=3,size=(500,),dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features=40, out_features=2):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(in_features, 13, bias=False)\n",
    "        self.linear2 = nn.Linear(13, 8, bias=False)\n",
    "        self.output = nn.Linear(8, out_features, bias=True)\n",
    "    def forward(self, x):\n",
    "        sigma1 = torch.relu(self.linear1(x))\n",
    "        sigma2 = torch.sigmoid(self.linear2(sigma1))\n",
    "        z_hat = self.output(sigma2)\n",
    "        return z_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = X.shape[1]\n",
    "output_ = len(y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(420)\n",
    "net = Model(in_features=input_, out_features=output_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "zhat = net.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义损失函数\n",
    "criterion = CEL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(zhat, y.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1559, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.0588e-04, -1.4974e-04, -7.3415e-04, -7.7351e-05, -2.6140e-04,\n",
       "         -1.1693e-04, -6.6626e-04, -5.1727e-04, -1.8854e-04, -8.5235e-05,\n",
       "         -1.5836e-04, -3.0359e-04, -1.8416e-04, -6.5027e-04, -2.1789e-04,\n",
       "         -1.3007e-04, -2.6011e-04, -8.8230e-06, -1.9348e-04, -1.7094e-04],\n",
       "        [ 2.0197e-02, -1.9837e-03,  2.4011e-02,  2.0821e-03,  1.0392e-02,\n",
       "          7.1134e-03,  1.2124e-02,  7.9953e-03,  2.9962e-02,  1.8190e-02,\n",
       "          1.2186e-02,  1.5038e-02,  2.7777e-02,  2.3854e-03,  1.7961e-02,\n",
       "          1.9643e-02,  3.5274e-02,  2.0755e-02,  3.3555e-03,  1.5672e-03],\n",
       "        [-2.0935e-02,  1.5948e-02,  6.0700e-03,  1.4997e-02,  8.6460e-03,\n",
       "          1.9749e-03,  1.8516e-02,  1.2732e-02, -1.1614e-02,  2.3176e-03,\n",
       "         -5.3246e-03,  1.2712e-02, -5.8676e-03, -8.9849e-03, -1.0081e-02,\n",
       "          1.6878e-02, -2.0688e-02, -1.7009e-02,  4.2748e-03, -2.4894e-03],\n",
       "        [-2.6928e-02, -2.1060e-02, -1.6663e-02, -3.1295e-02, -2.4752e-02,\n",
       "         -3.2839e-02, -1.9562e-02, -3.2352e-02, -1.5026e-02, -3.2441e-02,\n",
       "         -2.0851e-02, -1.5441e-02, -5.3087e-03, -2.8051e-02, -1.8855e-02,\n",
       "         -2.8417e-02, -1.9698e-02, -2.5054e-02, -3.8864e-02, -2.3602e-02],\n",
       "        [-4.8001e-02, -4.4099e-02, -3.8150e-02, -4.9610e-02, -2.9965e-02,\n",
       "         -2.8974e-02, -3.5683e-02, -5.0973e-02, -3.2001e-02, -6.4540e-02,\n",
       "         -1.2645e-02, -5.9685e-02, -9.1220e-03, -2.7520e-02, -3.1360e-02,\n",
       "         -4.8315e-02, -4.3296e-02, -2.9379e-02, -4.5372e-02, -4.0272e-02],\n",
       "        [-9.8198e-04,  2.5876e-03, -6.5588e-04, -1.1751e-03, -2.0547e-04,\n",
       "          2.8493e-03, -6.9864e-04,  1.9660e-03, -5.1527e-04, -2.9241e-04,\n",
       "         -8.9481e-04, -5.0707e-04,  3.8034e-04, -1.6837e-03,  5.0398e-04,\n",
       "          5.3067e-04,  5.3031e-04,  2.1466e-03,  2.0867e-03, -5.4963e-04],\n",
       "        [ 3.7335e-02,  4.0210e-02,  2.8663e-02,  3.4296e-02,  1.4204e-02,\n",
       "          5.8948e-02,  3.9279e-02,  3.3212e-02, -7.8144e-03,  1.0622e-01,\n",
       "          5.0682e-03,  7.9267e-02,  1.2186e-02,  4.5355e-02,  6.7229e-03,\n",
       "          6.0299e-02,  3.3652e-02,  3.2501e-02,  6.8229e-02,  5.9032e-02],\n",
       "        [ 5.1151e-02,  1.0585e-02,  1.3385e-02,  9.3803e-03,  1.6790e-02,\n",
       "          1.0455e-02,  6.2768e-03,  1.3815e-02,  5.5972e-02,  8.0274e-03,\n",
       "          2.0112e-02,  1.9806e-02,  2.8777e-02,  3.0089e-02,  3.5026e-02,\n",
       "          1.0238e-02,  4.0864e-02,  3.5842e-02,  2.4935e-02,  2.1755e-03],\n",
       "        [-5.2736e-02, -5.1716e-02, -5.9402e-02, -4.7006e-02, -4.8609e-02,\n",
       "         -6.7291e-02, -3.8731e-02, -4.6433e-02, -2.4121e-02, -7.4911e-02,\n",
       "         -2.8431e-02, -7.4328e-02, -3.3975e-02, -5.9400e-02, -4.0790e-02,\n",
       "         -7.2221e-02, -5.4907e-02, -3.9785e-02, -7.4967e-02, -8.0892e-02],\n",
       "        [ 6.1339e-03,  4.7897e-03,  1.1120e-02, -1.1151e-02, -1.0080e-02,\n",
       "         -1.3087e-02,  1.5551e-03, -1.5581e-02, -5.3538e-03, -1.1943e-03,\n",
       "         -3.5358e-03, -5.8719e-03,  1.5991e-03, -2.0462e-03, -3.2408e-03,\n",
       "          3.5685e-03,  1.7937e-03, -4.5950e-03,  4.3654e-03,  2.6570e-03],\n",
       "        [ 1.0269e-02,  3.5380e-03,  4.7906e-03,  6.9297e-03,  3.3180e-03,\n",
       "          1.1080e-03,  1.1425e-04,  1.8398e-03,  3.8047e-03,  6.4998e-03,\n",
       "          5.4116e-03,  2.1473e-03,  3.9768e-03,  4.2012e-03,  3.3341e-03,\n",
       "          2.2224e-03,  5.8587e-03,  8.3064e-03,  5.9622e-03,  5.2069e-03],\n",
       "        [-2.1960e-02, -2.3583e-02, -4.1890e-03, -1.0681e-02, -1.7831e-02,\n",
       "         -2.3164e-02, -1.1581e-02, -2.6361e-02, -3.6994e-02, -2.7501e-02,\n",
       "         -1.0480e-02, -1.5166e-02, -2.2039e-02, -2.9261e-02, -1.8966e-02,\n",
       "         -1.4273e-02, -2.6991e-02, -2.1449e-02, -2.0070e-02, -8.1069e-03],\n",
       "        [ 5.0811e-04,  7.6217e-04,  1.2227e-04,  1.0318e-03,  2.1124e-03,\n",
       "          1.9093e-03,  1.3490e-03,  2.1242e-03,  2.3083e-04,  3.6282e-03,\n",
       "          1.1032e-03,  1.3266e-03,  4.8912e-04,  3.8676e-04,  2.0948e-03,\n",
       "          3.9621e-04,  9.5046e-04,  3.2236e-03,  1.0570e-03,  4.8314e-04]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.linear1.weight.grad #还没有梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#与可以重复进行的正向传播不同，一次正向传播后，反向传播只能进行一次\n",
    "#如果希望能够重复进行反向传播，可以在进行第一次反向传播的时候加上参数retain_graph\n",
    "loss.backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.0882e-04, -2.2461e-04, -1.1012e-03, -1.1603e-04, -3.9210e-04,\n",
       "         -1.7540e-04, -9.9939e-04, -7.7591e-04, -2.8282e-04, -1.2785e-04,\n",
       "         -2.3754e-04, -4.5538e-04, -2.7624e-04, -9.7540e-04, -3.2683e-04,\n",
       "         -1.9511e-04, -3.9017e-04, -1.3234e-05, -2.9022e-04, -2.5642e-04],\n",
       "        [ 3.0296e-02, -2.9756e-03,  3.6016e-02,  3.1232e-03,  1.5588e-02,\n",
       "          1.0670e-02,  1.8185e-02,  1.1993e-02,  4.4943e-02,  2.7284e-02,\n",
       "          1.8279e-02,  2.2556e-02,  4.1665e-02,  3.5781e-03,  2.6942e-02,\n",
       "          2.9465e-02,  5.2911e-02,  3.1132e-02,  5.0333e-03,  2.3508e-03],\n",
       "        [-3.1402e-02,  2.3921e-02,  9.1050e-03,  2.2496e-02,  1.2969e-02,\n",
       "          2.9623e-03,  2.7773e-02,  1.9098e-02, -1.7421e-02,  3.4764e-03,\n",
       "         -7.9870e-03,  1.9068e-02, -8.8015e-03, -1.3477e-02, -1.5122e-02,\n",
       "          2.5317e-02, -3.1032e-02, -2.5513e-02,  6.4122e-03, -3.7341e-03],\n",
       "        [-4.0392e-02, -3.1590e-02, -2.4995e-02, -4.6943e-02, -3.7128e-02,\n",
       "         -4.9258e-02, -2.9343e-02, -4.8527e-02, -2.2539e-02, -4.8661e-02,\n",
       "         -3.1276e-02, -2.3161e-02, -7.9630e-03, -4.2076e-02, -2.8282e-02,\n",
       "         -4.2625e-02, -2.9548e-02, -3.7581e-02, -5.8296e-02, -3.5403e-02],\n",
       "        [-7.2002e-02, -6.6148e-02, -5.7226e-02, -7.4415e-02, -4.4947e-02,\n",
       "         -4.3461e-02, -5.3525e-02, -7.6459e-02, -4.8001e-02, -9.6810e-02,\n",
       "         -1.8968e-02, -8.9528e-02, -1.3683e-02, -4.1280e-02, -4.7039e-02,\n",
       "         -7.2472e-02, -6.4944e-02, -4.4069e-02, -6.8058e-02, -6.0408e-02],\n",
       "        [-1.4730e-03,  3.8815e-03, -9.8381e-04, -1.7627e-03, -3.0821e-04,\n",
       "          4.2739e-03, -1.0480e-03,  2.9489e-03, -7.7291e-04, -4.3862e-04,\n",
       "         -1.3422e-03, -7.6061e-04,  5.7051e-04, -2.5256e-03,  7.5597e-04,\n",
       "          7.9600e-04,  7.9547e-04,  3.2199e-03,  3.1301e-03, -8.2444e-04],\n",
       "        [ 5.6002e-02,  6.0315e-02,  4.2994e-02,  5.1444e-02,  2.1307e-02,\n",
       "          8.8421e-02,  5.8918e-02,  4.9818e-02, -1.1722e-02,  1.5934e-01,\n",
       "          7.6023e-03,  1.1890e-01,  1.8279e-02,  6.8033e-02,  1.0084e-02,\n",
       "          9.0448e-02,  5.0478e-02,  4.8752e-02,  1.0234e-01,  8.8549e-02],\n",
       "        [ 7.6726e-02,  1.5878e-02,  2.0077e-02,  1.4070e-02,  2.5185e-02,\n",
       "          1.5682e-02,  9.4153e-03,  2.0722e-02,  8.3959e-02,  1.2041e-02,\n",
       "          3.0168e-02,  2.9709e-02,  4.3166e-02,  4.5134e-02,  5.2539e-02,\n",
       "          1.5357e-02,  6.1296e-02,  5.3763e-02,  3.7402e-02,  3.2632e-03],\n",
       "        [-7.9105e-02, -7.7575e-02, -8.9104e-02, -7.0509e-02, -7.2914e-02,\n",
       "         -1.0094e-01, -5.8097e-02, -6.9650e-02, -3.6182e-02, -1.1237e-01,\n",
       "         -4.2647e-02, -1.1149e-01, -5.0963e-02, -8.9101e-02, -6.1185e-02,\n",
       "         -1.0833e-01, -8.2360e-02, -5.9677e-02, -1.1245e-01, -1.2134e-01],\n",
       "        [ 9.2009e-03,  7.1846e-03,  1.6679e-02, -1.6726e-02, -1.5119e-02,\n",
       "         -1.9630e-02,  2.3326e-03, -2.3371e-02, -8.0307e-03, -1.7914e-03,\n",
       "         -5.3037e-03, -8.8079e-03,  2.3987e-03, -3.0692e-03, -4.8613e-03,\n",
       "          5.3527e-03,  2.6906e-03, -6.8925e-03,  6.5481e-03,  3.9854e-03],\n",
       "        [ 1.5403e-02,  5.3069e-03,  7.1860e-03,  1.0395e-02,  4.9770e-03,\n",
       "          1.6620e-03,  1.7138e-04,  2.7597e-03,  5.7071e-03,  9.7496e-03,\n",
       "          8.1174e-03,  3.2209e-03,  5.9653e-03,  6.3019e-03,  5.0011e-03,\n",
       "          3.3336e-03,  8.7880e-03,  1.2460e-02,  8.9433e-03,  7.8103e-03],\n",
       "        [-3.2940e-02, -3.5374e-02, -6.2836e-03, -1.6022e-02, -2.6746e-02,\n",
       "         -3.4746e-02, -1.7372e-02, -3.9542e-02, -5.5490e-02, -4.1251e-02,\n",
       "         -1.5720e-02, -2.2749e-02, -3.3058e-02, -4.3892e-02, -2.8449e-02,\n",
       "         -2.1409e-02, -4.0486e-02, -3.2173e-02, -3.0104e-02, -1.2160e-02],\n",
       "        [ 7.6217e-04,  1.1433e-03,  1.8340e-04,  1.5477e-03,  3.1685e-03,\n",
       "          2.8640e-03,  2.0235e-03,  3.1864e-03,  3.4624e-04,  5.4422e-03,\n",
       "          1.6548e-03,  1.9899e-03,  7.3368e-04,  5.8013e-04,  3.1421e-03,\n",
       "          5.9432e-04,  1.4257e-03,  4.8354e-03,  1.5855e-03,  7.2471e-04]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.linear1.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 20])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.linear1.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 动量法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 手动实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#在这里，我们的数据是生成的随机数，为了让大家看出效果，所以我才设置了步长为10，正常不会使用这么大的步长\n",
    "#步长、学习率的英文是learning rate，所以常常简写为lr\n",
    "lr = 10\n",
    "dw = net.linear1.weight.grad\n",
    "w = net.linear1.weight.data\n",
    "#对任意w可以有\n",
    "w -= lr * dw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "普通梯度下降就是在重复正向传播、计算梯度、更新权重的过程，但这个过程往往非常漫长。如大家所见，步长设置为0.001时，我们看不到w任何的变化，只有当步长设置得非常巨大，我们才能够看到一些改变，但在之前的课程中我们说过，巨大的步长可能会让我们跳过真正的最小值，所以我们无法将步长设置得很大，无论如何，梯度下降都是一个缓慢的过程。在这个基础上，我们提出了加速迭代的数个方法，其中一个很关键的方法，就是使用动量Momentum。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v(t) = gamma * v(t-1)  - lr * dw\n",
    "# w(t+1) = w(t) + v(t)\n",
    "\n",
    "lr = 0.1\n",
    "gamma = 0.9\n",
    "dw = net.linear1.weight.grad\n",
    "w = net.linear1.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t = 1，走第一步，进行首次迭代的时候，需要一个v0\n",
    "v = torch.zeros(dw.shape[0], dw.shape[1])\n",
    "v = gamma * v - lr * dw\n",
    "w += v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 torch.optim实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "##导入库\n",
    "#确定数据、超参数的确定（lr，gamma）\n",
    "#定义伸进网络的架构类Model，类Model需要输入的参数\n",
    "##实例化神经网络的类 - 让神经网络准备好进行正向传播\n",
    "#定义损失函数\n",
    "#定义优化算法\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "#确定数据\n",
    "\n",
    "torch.manual_seed(420)\n",
    "X = torch.rand((500,20),dtype=torch.float32) * 100\n",
    "y = torch.randint(low=0,high=3,size=(500,),dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "gamma = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义神经网路的架构\n",
    "\"\"\"\n",
    "注意：这是一个三分类的神经网络，因此我们需要调用的损失函数多分类交叉熵函数CEL\n",
    "CEL类已经内置了softmax功能，因此我们需要修改一下网络架构，删除forward函数中输出层上的softmax函数，并将最终的输出修改为zhat\n",
    "\"\"\"\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,in_features=10,out_features=2):\n",
    "        super(Model,self).__init__() #super(请查找这个类的父类，请使用找到的父类替换现在的类)\n",
    "        self.linear1 = nn.Linear(in_features,13,bias=True) #输入层不用写，这里是隐藏层的第一层\n",
    "        self.linear2 = nn.Linear(13,8,bias=True)\n",
    "        self.output = nn.Linear(8,out_features,bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        sigma1 = torch.relu(self.linear1(x))\n",
    "        sigma2 = torch.sigmoid(self.linear2(sigma1))\n",
    "        zhat = self.output(sigma2)\n",
    "        return zhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = X.shape[1] #特征的数目\n",
    "output_ = len(y.unique()) #分类的数目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#实例化神经网络类\n",
    "torch.manual_seed(420)\n",
    "net = Model(in_features=input_, out_features=output_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x0000029D606F53C8>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.parameters() #一次性导出现有神经网络架构下全部的权重和截距"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "for x in net.parameters():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义损失函数\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义优化算法\n",
    "opt = optim.SGD(net.parameters()#需要进行迭代的权重\n",
    "                ,lr = lr\n",
    "                ,momentum = gamma\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#向前传播\n",
    "#本轮向前传播的损失函数值\n",
    "#反向传播 - 得到了梯度\n",
    "#更新权重（和动量）\n",
    "#清空梯度 - 清除原来计算出来的，基于上一个点的坐标计算的梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 20])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1005, grad_fn=<NllLossBackward>)\n",
      "tensor([ 0.1365, -0.1346,  0.2127, -0.1776, -0.0683, -0.1541,  0.1723,  0.0838,\n",
      "        -0.1116, -0.1730])\n"
     ]
    }
   ],
   "source": [
    "zhat = net.forward(X) #向前传播\n",
    "loss = criterion(zhat,y.reshape(500).long()) #损失函数值\n",
    "loss.backward() #反向传播\n",
    "opt.step() #更新权重w，从这一瞬间开始，坐标点就发生了变化，所有的梯度必须重新计算\n",
    "opt.zero_grad() #清除原来储存好的，基于上一个坐标点计算的梯度，为下一次计算梯度腾出空间\n",
    "\n",
    "print(loss)\n",
    "print(net.linear1.weight.data[0][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 MSGD介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSGD:\n",
    "- 优点：①能找到全局最小值；②计算速度加快\n",
    "- 缺点：迭代次数不清楚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在深度学习中，如果梯度下降的每次迭代都使用全部数据，将会非常耗费计算资源，且样本量越大，计算开销越高。虽然PyTorch被设计成天生能够处理巨量数据，但我们还是需要在数据量这一点上下功夫。这一节，我们开始介绍小批量随机梯度下降（mini-batch stochasticgradient descent，简写为mini-batch SGD）。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "小批量随机梯度下降是深度学习入门级的优化算法（梯度下降是入门级之下的），其求解与迭代流程与传统梯度下降（GD）基本一致，不过二者在迭代权重时使用的数据这一点上存在巨大的不同。传统梯度下降在每次进行权重迭代（即循环）时都使用全部数据，每次迭代所使用的数据也都一致。而minibatch SGD是每次迭代前都会从整体采样一批固定数目的样本组成批次（batch）B，并用B中的样本进行梯度计算，以减少样本量。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为什么会选择mini-batch SGD作为神经网络的入门级优化算法呢？有两个比较主流的原因。第一个是，比起传统梯度下降，mini-batch SGD更可能找到全局最小值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "传统梯度下降是每次迭代时都使用全部数据的梯度下降，所以每次使用的数据是一致的，因此梯度向量的方向和大小都只受到权重 的影响，所以梯度方向的变化相对较小，很多时候看起来梯度甚至是指向一个方向（如上图所示）。这样带来的优势是可以使用较大的步长，快速迭代直到找到最小值。但是缺点也很明显，由于梯度方向不容易发生巨大变化，所以一旦在迭代过程中落入局部最优的范围，传统梯度下降就很难跳出局部最优，再去寻找全局最优解了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./pics/损失函数和优化器/MSGD.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "而mini-batch SGD在每次迭代前都会随机抽取一批数据，所以每次迭代时带入梯度向量表达式的数据是不同的，梯度的方向同时受到系数 和带入的训练数据的影响，**因此每次迭代时梯度向量的方向都会发生较大变化**。并且，当抽样的数据量越小，本次迭代中使用的样本数据与上一次迭代中使用的样本数据之间的差异就可能越大，这也导致本次迭代中梯度的方向与上一次迭代中梯度的方向有巨大差异。所以对于mini-batch SGD而言，它的梯度下降路线看起来往往是曲折的折线（如上图所示）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "极端情况下，当我们每次随机选取的批量中只有一个样本时，梯度下降的迭代轨迹就会变得异常不稳定（如上图所示）。我们称这样的梯度下降为随机梯度下降（stochastic gradient descent，SGD）。mini-batch SGD的优势是算法不会轻易陷入局部最优，由于每次梯度向量的方向都会发生巨大变化，因此一旦有机会，算法就能够跳出局部最优，走向全局最优（当然也有可能是跳出一个局部最优，走向另一个局部最优）。**不过缺点是，需要的迭代次数变得不明**。如果最开始就在全局最优的范围内，那可能只需要非常少的迭代次数就收敛，但是如果最开始落入了局部最优的范围，或全局最优与局部最优的差异很小，那可能需要花很长的时间、经过很多次迭代才能够收敛，毕竟不断改变的方向会让迭代的路线变得曲折。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从整体来看，为了mini-batch SGD这“不会轻易被局部最优困住”的优点，我们在神经网络中使用它作为优化算法（或优化算法的基础）。当然，还有另一个流传更广、更为认知的理由支持我们使用minibatch SGD：mini-batch SGD可以提升神经网络的计算效率，让神经网络计算更快。为了解决计算开销大的问题，我们要使用mini-batch SGD。考虑到可以从全部数据中选出一部分作为全部数据的“近似估计\"，然后用选出的这一部分数据来进行迭代，每次迭代需要计算的数据量就会更少，计算消耗也会更少，因此神经网络的速度会提升。当然了，这并不是说使用1001个样本进行迭代一定比使用1000个样本进行迭代速度要慢，而是指每次迭代中计算上十万级别的数据，会比迭代中只计算一千个数据慢得多。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epoch是衡量训练数据被使用次数的单位，一个epoch表示优化算法将全部训练数据都使用了一次。它与梯度下降中的迭代次数有非常深的关系，我们常使用“完成1个epoch需要n次迭代“这样的语言。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 60 #请让神经网络学习60次全部数据\n",
    "batch = 10 #把全数据X划分为10个batch\n",
    "\n",
    "for epochs in range(epoch):\n",
    "    for batch in range(batch):\n",
    "        zhat = net.forward(X) #最后一个线性层的输出结果，向前传播\n",
    "        loss = criterion(zhat, y.reshape(500).long()) #计算损失函数\n",
    "        loss.backward()\n",
    "        opt.step() #步子，走一步，更新权重w，更新动量v\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 TenserDataset和DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要对数据进行采样、分割等操作。在PyTorch中，操作数据所需要使用的模块是torch.utils，其中utils.data类下面有大量用来执行数据预处理的工具。在MBSGD中，我们需要将数据划分为许多组特征张量+对应标签的形式，因此最开始我们要将数据的特征张量与标签打包成一个对象。之前我们提到过，深度学习中的特征张量维度很少是二维，因此其特征张量与标签几乎总是分开的，不像机器学习中标签常常出现在特征矩阵的最后一列或第一列。在我们之前的例子中，我们是单独生成了标签与特征张量，所以也需要合并，如果你的数据本来就是特征张量与标签在同一个张量中，那你可以跳过这一步。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合并张量与标签，我们所使用的类是utils.data.TensorDataset，这个功能类似于python中的zip，可以将最外面的维度一致的tensor进行打包，也就是将第一个维度一致的tensor进行打包。我们来看一下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.6375, -2.2982, -0.1133],\n",
       "         [ 0.5568,  0.2281,  0.2848]]),\n",
       " tensor([[[-0.2488,  0.9710, -0.0898, -1.6021,  0.4668],\n",
       "          [-1.1830, -0.6481, -0.2827, -0.8406,  1.2424],\n",
       "          [ 0.4588, -0.7573, -1.3363,  0.0340,  0.0669],\n",
       "          [ 0.7278,  1.5799, -0.1209,  0.5723,  0.5374]],\n",
       " \n",
       "         [[-0.4636,  0.0549, -0.5719, -0.0037,  0.5953],\n",
       "          [-0.3521,  0.4009,  1.1674, -0.7637,  0.8819],\n",
       "          [-0.8994, -2.3747,  1.2722, -0.5038, -0.4691],\n",
       "          [-0.0265,  1.6925,  0.7167,  0.5892, -0.4352]],\n",
       " \n",
       "         [[-0.7066,  0.2174,  0.0977, -0.7980, -1.9867],\n",
       "          [ 0.0781,  0.1157, -0.1451, -2.1414,  0.4255],\n",
       "          [ 1.0590, -0.8353, -0.4461, -0.2727, -1.1807],\n",
       "          [-1.2888, -0.1733, -0.3328,  0.4281, -1.7653]]]),\n",
       " tensor([0.4627]))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "a = torch.randn(500,2,3)\n",
    "b = torch.randn(500,3,4,5)\n",
    "c = torch.randn(500,1)\n",
    "TensorDataset(a,b,c)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4)\n",
      "(2, 5)\n",
      "(3, 6)\n"
     ]
    }
   ],
   "source": [
    "# 和zip还是不一样，实际上没有并到一起，但是在torch的训练时会一组一组读取\n",
    "for i in zip([1,2,3], [4,5,6]):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.6375, -2.2982, -0.1133],\n",
       "         [ 0.5568,  0.2281,  0.2848]]),\n",
       " tensor([0.4627]))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#试试看合并a与c，我们一般合并特征张量与标签，就是这样合并的\n",
    "TensorDataset(a,c)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Size mismatch between tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_22056/469403987.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#如果合并的tensor的最外层的维度不相等\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mTensorDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\conda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *tensors)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Size mismatch between tensors\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Size mismatch between tensors"
     ]
    }
   ],
   "source": [
    "#如果合并的tensor的最外层的维度不相等\n",
    "c = torch.randn(300,1)\n",
    "TensorDataset(a,c)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们将数据打包成一个对象之后，我们需要使用划分小批量的功能DataLoader。DataLoader是处理训练前专用的功能，它可以接受任意形式的数组、张量作为输入，并把他们一次性转换为神经网络可以接入的tensor。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.randn(500,3,4,5)\n",
    "c = torch.randn(500,1)\n",
    "data = TensorDataset(b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[ 6.7865e-01, -5.5162e-01,  2.1791e+00, -2.4237e-02, -1.4930e+00],\n",
      "          [-1.6076e+00,  5.5992e-01,  7.1593e-01, -5.9433e-01, -1.3133e+00],\n",
      "          [ 3.3145e-01,  3.4970e-01,  1.2913e+00,  4.4500e-01,  6.8841e-01],\n",
      "          [-9.9585e-01, -1.2249e+00,  3.0657e-01, -2.5904e+00, -2.9265e-01]],\n",
      "\n",
      "         [[ 4.1238e-01,  1.0195e+00,  4.4412e-01,  1.0168e-01, -4.7166e-01],\n",
      "          [ 4.0492e-01,  1.7901e-01,  2.9355e-01,  7.0473e-01,  4.4794e-01],\n",
      "          [-5.5782e-01, -1.2660e-03,  1.9333e-01,  1.7140e+00, -1.0123e-01],\n",
      "          [ 6.7576e-01,  5.3580e-01, -6.0712e-01, -8.5088e-01,  1.3299e+00]],\n",
      "\n",
      "         [[-2.1354e-02, -1.1275e+00,  7.4320e-01, -1.4692e+00,  7.7091e-03],\n",
      "          [ 1.1615e-01,  1.4128e+00,  1.2669e+00, -2.5619e-01, -1.5276e+00],\n",
      "          [-5.8195e-01, -4.7048e-01, -1.3230e+00, -4.6937e-01, -1.3707e+00],\n",
      "          [ 2.9066e-01, -6.8272e-01,  9.0702e-01, -5.1144e-01, -1.5555e-01]]]]), tensor([[-0.0907]])]\n"
     ]
    }
   ],
   "source": [
    "for x in DataLoader(data):\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataLoader(data\n",
    "          , batch_size = bs\n",
    "          , shuffle = True #划分小批量之前请随机打乱我们的数据\n",
    "          , drop_last = True #你要舍弃最后一个batch吗？\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 3, 4, 5])\n",
      "torch.Size([120, 3, 4, 5])\n",
      "torch.Size([120, 3, 4, 5])\n",
      "torch.Size([120, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "for i in dataset:\n",
    "    print(i[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset) #一共有多少个batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x29d601413c8>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 6.7865e-01, -5.5162e-01,  2.1791e+00, -2.4237e-02, -1.4930e+00],\n",
       "          [-1.6076e+00,  5.5992e-01,  7.1593e-01, -5.9433e-01, -1.3133e+00],\n",
       "          [ 3.3145e-01,  3.4970e-01,  1.2913e+00,  4.4500e-01,  6.8841e-01],\n",
       "          [-9.9585e-01, -1.2249e+00,  3.0657e-01, -2.5904e+00, -2.9265e-01]],\n",
       " \n",
       "         [[ 4.1238e-01,  1.0195e+00,  4.4412e-01,  1.0168e-01, -4.7166e-01],\n",
       "          [ 4.0492e-01,  1.7901e-01,  2.9355e-01,  7.0473e-01,  4.4794e-01],\n",
       "          [-5.5782e-01, -1.2660e-03,  1.9333e-01,  1.7140e+00, -1.0123e-01],\n",
       "          [ 6.7576e-01,  5.3580e-01, -6.0712e-01, -8.5088e-01,  1.3299e+00]],\n",
       " \n",
       "         [[-2.1354e-02, -1.1275e+00,  7.4320e-01, -1.4692e+00,  7.7091e-03],\n",
       "          [ 1.1615e-01,  1.4128e+00,  1.2669e+00, -2.5619e-01, -1.5276e+00],\n",
       "          [-5.8195e-01, -4.7048e-01, -1.3230e+00, -4.6937e-01, -1.3707e+00],\n",
       "          [ 2.9066e-01, -6.8272e-01,  9.0702e-01, -5.1144e-01, -1.5555e-01]]]),\n",
       " tensor([-0.0907]))"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dataset[0] #单个样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 6.7865e-01, -5.5162e-01,  2.1791e+00, -2.4237e-02, -1.4930e+00],\n",
       "         [-1.6076e+00,  5.5992e-01,  7.1593e-01, -5.9433e-01, -1.3133e+00],\n",
       "         [ 3.3145e-01,  3.4970e-01,  1.2913e+00,  4.4500e-01,  6.8841e-01],\n",
       "         [-9.9585e-01, -1.2249e+00,  3.0657e-01, -2.5904e+00, -2.9265e-01]],\n",
       "\n",
       "        [[ 4.1238e-01,  1.0195e+00,  4.4412e-01,  1.0168e-01, -4.7166e-01],\n",
       "         [ 4.0492e-01,  1.7901e-01,  2.9355e-01,  7.0473e-01,  4.4794e-01],\n",
       "         [-5.5782e-01, -1.2660e-03,  1.9333e-01,  1.7140e+00, -1.0123e-01],\n",
       "         [ 6.7576e-01,  5.3580e-01, -6.0712e-01, -8.5088e-01,  1.3299e+00]],\n",
       "\n",
       "        [[-2.1354e-02, -1.1275e+00,  7.4320e-01, -1.4692e+00,  7.7091e-03],\n",
       "         [ 1.1615e-01,  1.4128e+00,  1.2669e+00, -2.5619e-01, -1.5276e+00],\n",
       "         [-5.8195e-01, -4.7048e-01, -1.3230e+00, -4.6937e-01, -1.3707e+00],\n",
       "         [ 2.9066e-01, -6.8272e-01,  9.0702e-01, -5.1144e-01, -1.5555e-01]]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0907])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.batch_size #查看现有的batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于小批量随机梯度下降而言，我们一般这样使用TensorDataset与DataLoader:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "torch.manual_seed(420)\n",
    "X = torch.rand((50000,20),dtype=torch.float32) * 100 #要进行迭代了，增加样本数量\n",
    "y = torch.randint(low=0,high=3,size=(50000,1),dtype=torch.float32)\n",
    "epochs = 4\n",
    "bs = 4000\n",
    "data = TensorDataset(X,y)\n",
    "batchdata = DataLoader(data, batch_size=bs, shuffle = True)\n",
    "len(batchdata) #查看具体被分了多少个batch\n",
    "#可以使用.datasets查看数据集相关的属性\n",
    "len(batchdata.dataset) #总共有多少数据\n",
    "batchdata.dataset[0] #查看其中一个样本\n",
    "batchdata.dataset[0][0]#一个样本的特征张量\n",
    "batchdata.dataset[0][1]#一个样本的标签\n",
    "#属性batch_size，查看现在的batch_size是多少\n",
    "batchdata.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4000, 20])\n",
      "torch.Size([4000, 1])\n",
      "tensor([[24.4804, 88.4311, 90.7928,  ..., 66.4178, 91.6913, 86.2798],\n",
      "        [11.3812, 60.5861, 85.4907,  ..., 64.7298, 50.4029, 17.6171],\n",
      "        [36.8907, 88.6091, 51.1426,  ..., 26.4396, 28.1520, 25.4440],\n",
      "        ...,\n",
      "        [66.3327, 92.1414,  8.1029,  ..., 81.5257, 89.6613, 32.9947],\n",
      "        [66.0353, 96.5900, 93.1599,  ..., 93.1735, 66.7829, 39.6237],\n",
      "        [36.9158,  9.0684, 23.7006,  ...,  0.9979, 20.7019, 47.3606]]) tensor([[2.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [2.],\n",
      "        [1.],\n",
      "        [2.]])\n",
      "torch.Size([4000, 20])\n",
      "torch.Size([4000, 1])\n",
      "tensor([[4.6021e+00, 9.2652e+01, 2.4196e+01,  ..., 4.8241e+01, 5.2453e+01,\n",
      "         2.9459e+01],\n",
      "        [2.4702e+01, 1.6894e+01, 8.5195e+01,  ..., 4.7593e+01, 7.8934e+01,\n",
      "         6.3864e+01],\n",
      "        [9.4442e+01, 4.5311e+01, 7.7364e+01,  ..., 8.3494e+01, 4.2660e+01,\n",
      "         3.3664e+01],\n",
      "        ...,\n",
      "        [7.5925e+01, 5.5428e+01, 7.8092e+01,  ..., 2.2697e+01, 2.2982e+00,\n",
      "         8.8514e+01],\n",
      "        [1.0986e+00, 1.2401e-01, 6.1756e+01,  ..., 8.1108e+01, 3.8119e+01,\n",
      "         2.0843e+01],\n",
      "        [6.8868e+00, 5.6327e+01, 2.3217e+00,  ..., 4.3630e+01, 8.3586e+01,\n",
      "         5.8484e-02]]) tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "torch.Size([4000, 20])\n",
      "torch.Size([4000, 1])\n",
      "tensor([[75.3559,  2.5358, 72.2070,  ..., 86.8588, 70.2838, 75.9808],\n",
      "        [41.7118, 27.6322, 78.0920,  ..., 51.5066, 96.0304, 37.1771],\n",
      "        [51.2200, 47.4708, 74.2579,  ..., 19.4177, 80.1789, 91.3563],\n",
      "        ...,\n",
      "        [79.1032, 19.2684, 20.3089,  ..., 12.1598, 93.6500,  3.8033],\n",
      "        [ 0.4250, 10.2192, 76.5287,  ..., 44.5272, 24.6581, 51.0365],\n",
      "        [89.6666, 95.0687, 68.6656,  ..., 22.4083, 81.6246, 46.5633]]) tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [2.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "#我们在迭代的时候，常常这样使用：\n",
    "for batch_idx, (x,y) in enumerate(batchdata):\n",
    "    #sigma = net(x)\n",
    "    #loss = lossfn(sigma, y)\n",
    "    #loss.backward()\n",
    "    #opt.step()\n",
    "    #opt.zero_grad()\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    print(x,y)\n",
    "    if batch_idx == 2:\n",
    "        break #为了演示用，所以打断，在正常的循环里是不会打断的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 MINST-FASHION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本节课我们讲解了神经网络使用小批量随机梯度下降进行迭代的流程，现在我们要整合本节课中所有的\n",
    "代码实现一个完整的训练流程。首先要梳理一下整个流程：\n",
    "- 1）设置步长 ，动量值 ，迭代次数 ，batch_size等信息，（如果需要）设置初始权重\n",
    "- 2）导入数据，将数据切分成batches\n",
    "- 3）定义神经网络架构\n",
    "- 4）定义损失函数 ，如果需要的话，将损失函数调整成凸函数，以便求解最小值\n",
    "- 5）定义所使用的优化算法\n",
    "- 6）开始在epoches和batch上循环，执行优化算法：\n",
    " 6.1）调整数据结构，确定数据能够在神经网络、损失函数和优化算法中顺利运行\n",
    " 6.2）完成向前传播，计算初始损失\n",
    " 6.3）利用反向传播，在损失函数 上对每一个 求偏导数\n",
    " 6.4）迭代当前权重\n",
    " 6.5）清空本轮梯度\n",
    " 6.6）完成模型进度与效果监控\n",
    "- 7）输出结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 导库，设置各种初始值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "#确定数据、确定优先需要设置的值\n",
    "lr = 0.15\n",
    "gamma = 0\n",
    "epochs = 10\n",
    "bs = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 导入数据，分割小批量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载到了自定义目录的FashionMNIST中，大小134MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms #处理数据模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./FashionMNIST\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11.7%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "31.4%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "50.9%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "70.6%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "91.0%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./FashionMNIST\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to ./FashionMNIST\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./FashionMNIST\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.6%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./FashionMNIST\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to ./FashionMNIST\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./FashionMNIST\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "66.7%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./FashionMNIST\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "119.3%\n",
      "F:\\conda\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./FashionMNIST\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./FashionMNIST\\FashionMNIST\\raw\n",
      "\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "mnist = torchvision.datasets.FashionMNIST(root = \"./FashionMNIST\" #你的计算机上的某个目录\n",
    "                                          , download = True\n",
    "                                          , train = True\n",
    "                                          , transform = transforms.ToTensor()\n",
    "                                         ) #实例化数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./FashionMNIST\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist #对于数据的一个说明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.data.shape #特征张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.targets.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist[0][0].view(28,28).numpy()); #imageshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist[1][0].view(28,28).numpy());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist[30001][0].view(28,28).numpy());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchdata = DataLoader(mnist\n",
    "                       ,batch_size = bs\n",
    "                       ,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "for x,y in batchdata:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(500,20) - 20\n",
    "#x - 四维 （128,28*28）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = mnist.data[0].numel() #请问这个张量中总共有多少元素呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ = len(mnist.targets.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 定义神经网络的架构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features=10, out_features=2):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(in_features,1280,bias=False)\n",
    "        self.output = nn.Linear(1280,out_features, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1,28*28)\n",
    "        sigma1 = torch.relu(self.linear1(x))\n",
    "        sigma2 = F.log_softmax(self.output(sigma1),dim=1)\n",
    "        return sigma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60, 20])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view(-1,) #需要对数据结构进行一个改变，-1作为占位符，表示请pytorch帮助我们自动计算-1这个位置的维度应是多少\n",
    "x = torch.randn(30,40)\n",
    "x = x.view(-1,20)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义损失函数、优化算法、梯度下降的流程\n",
    "#定义一个训练函数\n",
    "#128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468.75"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnist) / bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batchdata)-1 #469个batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.752"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "469/125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 定义训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(net,bacthdata,lr=0.01, epochs=5, gamma = 0):\n",
    "    criterion = nn.NLLLoss()\n",
    "    opt = optim.SGD(net.parameters(),lr=lr,momentum = gamma)\n",
    "    correct = 0 #循环开始之前，预测正确的值为0\n",
    "    samples = 0 #循环开始之前，模型一个样本都没有见过\n",
    "    for epoch in range(epochs): #全数据被训练几次\n",
    "        for batch_idx,(x,y) in enumerate(batchdata):\n",
    "            y = y.view(x.shape[0]) #降维\n",
    "            sigma = net.forward(x) #正向传播\n",
    "            loss = criterion(sigma,y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            \n",
    "            #求解准确率，全部判断正确的样本数量/已经看过的总样本量\n",
    "            yhat = torch.max(sigma, 1)[1] #torch.max函数结果中的索引为1的部分\n",
    "            correct += torch.sum(yhat == y)\n",
    "            samples += x.shape[0]\n",
    "            #每训练一个batch的数据，模型见过的数据就会增加x.shape[0]\n",
    "            \n",
    "            if (batch_idx + 1) % 125 == 0 or batch_idx == len(batchdata)-1: #每N个batch我就打印一次\n",
    "                print(\"Epoch{}:[{}/{}({:.0f}%)],Loss:{:.6f},Accuracy:{:.3f}\".format(\n",
    "                    epoch+1\n",
    "                    ,samples\n",
    "                    ,epochs*len(batchdata.dataset)\n",
    "                    ,100*samples/(epochs*len(batchdata.dataset))\n",
    "                    ,loss.data.item()\n",
    "                    ,float(100*correct/samples)\n",
    "                     ))\n",
    "            #分子代表：已经查看过的数据有多少\n",
    "            #分母代表：在现有的epochs设置，模型一共需要查看多少数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "实验一下，这里是值A\n"
     ]
    }
   ],
   "source": [
    "print(\"实验一下，这里是值{}\".format(\"A\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = [\"A\",\"B\",\"C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'A')\n",
      "(1, 'B')\n",
      "(2, 'C')\n"
     ]
    }
   ],
   "source": [
    "for x in enumerate(list):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = torch.tensor([[0.3,0.4,0.25],[0.7,0.2,0.1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3000, 0.4000, 0.2500],\n",
       "        [0.7000, 0.2000, 0.1000]])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(l,1)[1] #softmax的预测标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = torch.tensor([True,False,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(l) #True = 1, False = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 进行训练和评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1:[16000/600000(3%)],Loss:0.727888,Accuracy:68.819\n",
      "Epoch1:[32000/600000(5%)],Loss:0.513726,Accuracy:73.550\n",
      "Epoch1:[48000/600000(8%)],Loss:0.459364,Accuracy:76.173\n",
      "Epoch1:[60000/600000(10%)],Loss:0.563562,Accuracy:77.373\n",
      "Epoch2:[76000/600000(13%)],Loss:0.433777,Accuracy:78.687\n",
      "Epoch2:[92000/600000(15%)],Loss:0.363204,Accuracy:79.634\n",
      "Epoch2:[108000/600000(18%)],Loss:0.443800,Accuracy:80.304\n",
      "Epoch2:[120000/600000(20%)],Loss:0.442278,Accuracy:80.723\n",
      "Epoch3:[136000/600000(23%)],Loss:0.543707,Accuracy:81.285\n",
      "Epoch3:[152000/600000(25%)],Loss:0.354620,Accuracy:81.691\n",
      "Epoch3:[168000/600000(28%)],Loss:0.526626,Accuracy:82.088\n",
      "Epoch3:[180000/600000(30%)],Loss:0.411618,Accuracy:82.367\n",
      "Epoch4:[196000/600000(33%)],Loss:0.350448,Accuracy:82.678\n",
      "Epoch4:[212000/600000(35%)],Loss:0.345022,Accuracy:83.008\n",
      "Epoch4:[228000/600000(38%)],Loss:0.474553,Accuracy:83.263\n",
      "Epoch4:[240000/600000(40%)],Loss:0.324190,Accuracy:83.479\n",
      "Epoch5:[256000/600000(43%)],Loss:0.317327,Accuracy:83.738\n",
      "Epoch5:[272000/600000(45%)],Loss:0.369660,Accuracy:83.957\n",
      "Epoch5:[288000/600000(48%)],Loss:0.341690,Accuracy:84.139\n",
      "Epoch5:[300000/600000(50%)],Loss:0.547992,Accuracy:84.282\n",
      "Epoch6:[316000/600000(53%)],Loss:0.292443,Accuracy:84.497\n",
      "Epoch6:[332000/600000(55%)],Loss:0.276111,Accuracy:84.649\n",
      "Epoch6:[348000/600000(58%)],Loss:0.318102,Accuracy:84.797\n",
      "Epoch6:[360000/600000(60%)],Loss:0.308750,Accuracy:84.874\n",
      "Epoch7:[376000/600000(63%)],Loss:0.261769,Accuracy:85.029\n",
      "Epoch7:[392000/600000(65%)],Loss:0.467604,Accuracy:85.163\n",
      "Epoch7:[408000/600000(68%)],Loss:0.374349,Accuracy:85.302\n",
      "Epoch7:[420000/600000(70%)],Loss:0.374845,Accuracy:85.384\n",
      "Epoch8:[436000/600000(73%)],Loss:0.292379,Accuracy:85.498\n",
      "Epoch8:[452000/600000(75%)],Loss:0.274055,Accuracy:85.624\n",
      "Epoch8:[468000/600000(78%)],Loss:0.326614,Accuracy:85.734\n",
      "Epoch8:[480000/600000(80%)],Loss:0.377757,Accuracy:85.793\n",
      "Epoch9:[496000/600000(83%)],Loss:0.345958,Accuracy:85.884\n",
      "Epoch9:[512000/600000(85%)],Loss:0.334107,Accuracy:85.993\n",
      "Epoch9:[528000/600000(88%)],Loss:0.161249,Accuracy:86.080\n",
      "Epoch9:[540000/600000(90%)],Loss:0.305421,Accuracy:86.151\n",
      "Epoch10:[556000/600000(93%)],Loss:0.309134,Accuracy:86.249\n",
      "Epoch10:[572000/600000(95%)],Loss:0.341859,Accuracy:86.330\n",
      "Epoch10:[588000/600000(98%)],Loss:0.308504,Accuracy:86.419\n",
      "Epoch10:[600000/600000(100%)],Loss:0.214857,Accuracy:86.484\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(420)\n",
    "net = Model(in_features=input_, out_features=output_)\n",
    "fit(net,batchdata,lr=lr,epochs=epochs,gamma=gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们现在已经完成了一个最基本的、神经网络训练并查看训练结果的代码，是不是感觉已经获得了很多支持呢？我们的模型最后得到的结果属于中规中矩，毕竟我们设置的网格结构只是最普通的全连接层，并且我们并没有对数据进行任何的处理或增强（在神经网络架构中，有被注释掉的两行关于batchnormalization的代码，取消注释，你会看到神经网络的准确率瞬间增加了5%，这是常用的处理之一）。已经成熟的、更加稳定的神经网络架构可以很轻易在MINST-FASHION数据集上获得99%的准确率，因此我们还有很长的路要走。从下节课开始，我们将学习更完整的训练流程，并学习神经网络性能与效果优化相关的更多内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
