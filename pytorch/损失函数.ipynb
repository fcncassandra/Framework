{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import MSELoss #Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = torch.randn(size=(50,),dtype=torch.float32)\n",
    "y = torch.randn(size=(50,),dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = MSELoss(reduction = \"sum\")\n",
    "# MSEloss(reduction = \"mean\"/\"sum\") #MSE #SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(yhat,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(86.6319)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 二分类交叉熵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 手动实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$L(w) = \\sum_{i=1}^m(y_i*ln(\\sigma_i) + (1-y_i)*ln(1-\\sigma_i))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 3*pow(10,3)\n",
    "\n",
    "torch.random.manual_seed(420)\n",
    "X = torch.rand((m,4),dtype=torch.float32)\n",
    "w = torch.rand((4,1),dtype=torch.float32)\n",
    "y = torch.randint(low=0,high=2,size=(m,1),dtype=torch.float32)\n",
    "zhat = torch.mm(X,w)\n",
    "sigma = torch.sigmoid(zhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss  = -(1/m) * sum(y * torch.log(sigma) + (1-y) * torch.log(1-sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7962])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，在写损失函数这样的复杂函数时，除了普通的加减乘除以外的全部计算，都要使用torch中的函数，因为tensor的运算速度是远远超过普通Python代码，甚至是NumPy的。你可以试着比较在样本量为300W时，以下两行代码运行的时间差异"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 3 * pow(10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((m, 4), dtype=torch.float32)\n",
    "w = torch.rand((4, 1), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.randint(low=0, high=2, size=(m,1), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        ...,\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((m,4),dtype=torch.float32)\n",
    "w = torch.rand((4,1),dtype=torch.float32)\n",
    "y = torch.randint(low=0,high=2,size=(m,1),dtype=torch.float32)\n",
    "zhat = torch.mm(X,w)\n",
    "sigma = torch.sigmoid(zhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python原生"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0851020812988281\n"
     ]
    }
   ],
   "source": [
    "start = time.time() #捕获现在的时间\n",
    "loss1 = -(1/m)*sum(y*torch.log(sigma) + (1-y)*torch.log(1-sigma))\n",
    "now = time.time() #以秒计\n",
    "print(now - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001994609832763672\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "loss2 = -(1/m)*torch.sum(y*torch.log(sigma) + (1-y)*torch.log(1-sigma))\n",
    "now = time.time() #以秒计\n",
    "print(now - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2种转成Numpy的写法\n",
    "np_sigma = torch.sigmoid(zhat).numpy() \n",
    "np_y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003989219665527344\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "loss3 = - (1/m) * np.sum(np_y*np.log(np_sigma) + (1-np_y)*np.log(1-np_sigma))\n",
    "now = time.time()\n",
    "print(now - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 交叉熵实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有nn中的2个，还有functional库中的2个，推荐nn.BCEWithLogitsLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7608)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.BCELoss(reduction = \"mean\") # none sum mean\n",
    "loss = criterion(sigma,y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7608)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pytorch官方更加推荐，因为内置的sigmoid函数可以让精度问题被缩小\n",
    "criterion2 = nn.BCEWithLogitsLoss(reduction = \"mean\")\n",
    "loss = criterion2(zhat, y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7608)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "#直接调用functional库中的计算函数\n",
    "F.binary_cross_entropy_with_logits(zhat,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7608)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.binary_cross_entropy(sigma,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 多分类交叉熵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二分类单样本使用这样的表示：$P = (\\hat y_i|x_i,w) = P_1^{y_i}*P_0^{1-y_i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多分类单样本使用这的表示：$P = (\\hat y_i|x_i,w) = P_1^{y_{i(k=1)}}*P_2^{y_{i(k=2)}}*...*P_k^{y_{i(k=K)}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于仅为真实类别时才会有结果，所以可以简化为：$P = (\\hat y_i|x_i,w) = P_j^{y_{i(k=j)}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多样本下的损失函数是：$L(w) = - \\sum_{i=1}^my_{i(k=j)}ln\\sigma_i$  \n",
    "$ln\\sigma_i$是对softmax计算的结果取Ln  \n",
    "$- \\sum_{i=1}^my_{i(k=j)}$是负对数似然函数NLLLoss：Negative Log Likelihood function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 3 * pow(10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(420)\n",
    "X = torch.rand((m, 4), dtype=torch.float32)\n",
    "w = torch.rand((4, 3), dtype=torch.float32)\n",
    "y = torch.randint(low=0, high=3, size=(m,), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_hat = torch.mm(X, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1139, -0.8802, -1.3585],\n",
       "        [-1.0558, -0.8982, -1.4075],\n",
       "        [-1.0920, -1.0626, -1.1430],\n",
       "        ...,\n",
       "        [-1.0519, -0.9180, -1.3805],\n",
       "        [-1.0945, -1.1219, -1.0798],\n",
       "        [-1.0276, -0.8891, -1.4649]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logsm = nn.LogSoftmax(dim=1)\n",
    "log_sigma = logsm(z_hat)\n",
    "log_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2.,  ..., 2., 2., 2.])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1147)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.NLLLoss() #实例化\n",
    "#由于交叉熵损失需要将标签转化为独热形式，因此不接受浮点数作为标签的输入\n",
    "#对NLLLoss而言，需要输入logsigma\n",
    "criterion(log_sigma, y.long())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用nn的更快"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1147)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(z_hat, y.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
